from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt


# Load dataset
(trainX, trainy), (testX, testy) = mnist.load_data()


# Reshape to include channel dimension (since MNIST is grayscale, the  channel is 1)
trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
testX = testX.reshape((testX.shape[0], 28, 28, 1))


trainX, testX = trainX.astype('float32') / 255.0, testX.astype('float32') / 255.0
# One hot encode the labels
trainy = to_categorical(trainy)
testy = to_categorical(testy)


# Visualize some examples
for i in range(9):
 plt.subplot(330 + 1 + i)
 plt.imshow(trainX[i].reshape(28, 28), cmap=plt.get_cmap('gray'))
plt.show()


# Step 2: Defining the Model's Architecture
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import SGD


# Build the model
model = Sequential()


# Add layers
model.add(Conv2D(32, (3, 3), activation='relu',
kernel_initializer='he_uniform', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(100, activation='relu',
kernel_initializer='he_uniform'))
model.add(Dense(10, activation='softmax'))


# Compile the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])


# Data augmentation to improve performance
datagen = ImageDataGenerator(width_shift_range=0.1,
height_shift_range=0.1, horizontal_flip=False)
datagen.fit(trainX)


history = model.fit(datagen.flow(trainX, trainy, batch_size=32),
 steps_per_epoch=int(len(trainX) / 32),
 epochs=10,
 validation_data=(testX, testy))


# Step 4: Estimating the Model's Performance
# Evaluate the model
_, accuracy = model.evaluate(testX, testy, verbose=0)
print(f'Accuracy: {accuracy * 100:.2f}%')


# Plot learning curves
plt.subplot(211)
plt.title('Cross Entropy Loss')
plt.plot(history.history['loss'], color='blue', label='train')
plt.plot(history.history['val_loss'], color='orange', label='test')
plt.legend()


plt.subplot(212)
plt.title('Classification Accuracy')
plt.plot(history.history['accuracy'], color='blue', label='train')
plt.plot(history.history['val_accuracy'], color='orange', label='test')
plt.legend()
plt.show()
